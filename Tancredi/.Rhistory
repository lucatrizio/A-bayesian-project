n <- length(data)
for (perm in 1:B) {
refl <- rbinom(n, 1, 0.5) * 2 - 1
T_perm[perm] <- abs(median(data_trans * refl))
}
return(sum(T_perm >= T0)/B)
}
grid=seq(80,110,by=0.1)
perm_wrapper <- function(grid_point) {
uni_t_perm(v, grid_point, B = 1000)
}
pval_function <- sapply(grid, perm_wrapper)
alpha <- 0.05
values.within.CI <- grid[pval_function > alpha]
CI <- range(values.within.CI)
##### plotting #####
plot(grid, pval_function, type = "l")  # plot p-value function
abline(v=CI[1], col="red")
abline(v=CI[2], col="red")
set.seed(2024)
v = data_vieux[,10]
hist(v)
# Let’s calculate a confidence interval around the median of this distribution, that is…
mu0 = median(v)
## [1] 0.08800729
uni_t_perm <- function(data, mu0, B = 1000) {
data_trans <- data - mu0
T0 <- abs(median(data_trans))
T_perm <- numeric(B)
n <- length(data)
for (perm in 1:B) {
refl <- rbinom(n, 1, 0.5) * 2 - 1
T_perm[perm] <- abs(median(data_trans * refl))
}
return(sum(T_perm >= T0)/B)
}
grid=seq(85,95,by=0.05)
perm_wrapper <- function(grid_point) {
uni_t_perm(v, grid_point, B = 1000)
}
pval_function <- sapply(grid, perm_wrapper)
alpha <- 0.1
values.within.CI <- grid[pval_function > alpha]
CI <- range(values.within.CI)
##### plotting #####
plot(grid, pval_function, type = "l")  # plot p-value function
abline(v=CI[1], col="red")
abline(v=CI[2], col="red")
set.seed(2024)
v = data_vieux[,10]
hist(v)
# Let’s calculate a confidence interval around the median of this distribution, that is…
mu0 = median(v)
## [1] 0.08800729
uni_t_perm <- function(data, mu0, B = 1000) {
data_trans <- data - mu0
T0 <- abs(median(data_trans))
T_perm <- numeric(B)
n <- length(data)
for (perm in 1:B) {
refl <- rbinom(n, 1, 0.5) * 2 - 1
T_perm[perm] <- abs(median(data_trans * refl))
}
return(sum(T_perm >= T0)/B)
}
grid=seq(85,110,by=0.05)
perm_wrapper <- function(grid_point) {
uni_t_perm(v, grid_point, B = 1000)
}
pval_function <- sapply(grid, perm_wrapper)
alpha <- 0.1
values.within.CI <- grid[pval_function > alpha]
CI <- range(values.within.CI)
##### plotting #####
plot(grid, pval_function, type = "l")  # plot p-value function
abline(v=CI[1], col="red")
abline(v=CI[2], col="red")
CI
library(survival)
library(survminer)
library(dplyr)
library(ggplot2)
library(knitr)
library(broom)
library(tidyr)
df = data.frame(df2)
View(df)
colnames(df)
View(df2)
help(na)
help(NA)
status = which(is.na(df[3]))
event = which(is.na(df[3]))
status <- rep(1, times=nrow(df))
status[event] = 0
fit <- survfit(Surv(df.tte.time.to.fall, status==2) ~ 1, data = df)
event = which(is.na(df[3]))
status <- rep(1, times=nrow(df))
status[event] = 0
fit <- survfit(Surv(df.tte.time.to.fall, status==2) ~ 1, data = df)
plot(fit, conf.int = T, xlab='Time [days]', ylab = 'Survival Probability', col='red',
main="Kaplan-Meier Curve")
event = which(is.na(df[3]))
status <- rep(1, times=nrow(df))
status[event] = 0
df$status = status
fit <- survfit(Surv(df.tte.time.to.fall, status==2) ~ 1, data = df)
plot(fit, conf.int = T, xlab='Time [days]', ylab = 'Survival Probability', col='red',
main="Kaplan-Meier Curve")
View(df)
df$status = status
df[,3]
fit <- survfit(Surv(df.tte.time.to.fall, status==1) ~ 1, data = df)
plot(fit, conf.int = T, xlab='Time [days]', ylab = 'Survival Probability', col='red',
main="Kaplan-Meier Curve")
rm(list = ls())
df = readRDS("/home/lixio/Desktop/2023-2024/1_semester/Nonparametric_statistics/tde/feb2024 (1).rds")
df1 = df[1]
df2 = df[2]
data = data.frame(df1)[,-c(1,2)]
data_full = data.frame(df1)
df_pere = data_full[which(data_full[,2] == "Le Père Duchesne"),]
df_vieux = data_full[which(data_full[,2] == "Le Vieux Cordelier"),]
data_pere = df_pere[,-c(1,2)]
data_vieux = df_vieux[,-c(1,2)]
library(survival)
library(survminer)
library(dplyr)
library(ggplot2)
library(knitr)
library(broom)
library(tidyr)
df = data.frame(df2)
event = which(is.na(df[3]))
status <- rep(1, times=nrow(df))
status[event] = 0
df$status = status
fit <- survfit(Surv(df.tte.time.to.fall, status==1) ~ 1, data = df)
plot(fit, conf.int = T, xlab='Time [days]', ylab = 'Survival Probability', col='red',
main="Kaplan-Meier Curve")
View(df)
df = data.frame(df2)
df_pere = df[which(df[,2] =="Le Père Duchesne")
df_viuex = df[whichdf[,2] != "Le Père Duchesne")
df = data.frame(df2)
df_pere = df[which(df[,2] =="Le Père Duchesne"]
df = data.frame(df2)
df_pere = df[which(df[,2] =="Le Père Duchesne")]
df = data.frame(df2)
df_pere = df[which(df[,2] =="Le Père Duchesne"),]
df_viuex = df[whichdf[,2] != "Le Père Duchesne"),]
df = data.frame(df2)
df_pere = df[which(df[,2] =="Le Père Duchesne"),]
df_viuex = df[which(df[,2] != "Le Père Duchesne"),]
df = data.frame(df2)
df_pere = df[which(df[,2] =="Le Père Duchesne"),]
df_vieux = df[which(df[,2] != "Le Père Duchesne"),]
event = which(is.na(df[3]))
status <- rep(1, times=nrow(df))
status[event] = 0
df$status = status
fit <- survfit(Surv(df.tte.time.to.fall, status==1) ~ df.tte.Journal, data = df)
plot(fit, conf.int = T, xlab='Time [days]', ylab = 'Survival Probability', col='red',
main="Kaplan-Meier Curve")
event = which(is.na(df[3]))
status <- rep(1, times=nrow(df))
status[event] = 0
df$status = status
fit <- survfit(Surv(df.tte.time.to.fall, status==1) ~ df.tte.Journal, data = df)
ggsurvplot(fit, conf.int = F, risk.table.col = "strata", legend='none')
ggsurvplot(fit, conf.int = T,
risk.table = TRUE, # Add risk table
risk.table.col = "strata", # Change risk table color by groups
surv.median.line = "hv", # Specify median survival
ggtheme = theme_bw(), # Change ggplot2 theme
break.time.by=90,
legend.labs=c("Pere","Vieux"), legend.title="Journal",
palette=c("darkblue","cyan3"),
title="Kaplan-Meier Curves ")
ggsurvplot(fit, conf.int = F,
risk.table = TRUE, # Add risk table
risk.table.col = "strata", # Change risk table color by groups
surv.median.line = "hv", # Specify median survival
ggtheme = theme_bw(), # Change ggplot2 theme
break.time.by=90,
legend.labs=c("Pere","Vieux"), legend.title="Journal",
palette=c("darkblue","cyan3"),
title="Kaplan-Meier Curves ")
df1 = df[1]
df2 = df[2]
data = data.frame(df1)[,-c(1,2)]
data_full = data.frame(df1)
df_pere = data_full[which(data_full[,2] == "Le Père Duchesne"),]
rm(list = ls())
df = readRDS("/home/lixio/Desktop/2023-2024/1_semester/Nonparametric_statistics/tde/feb2024 (1).rds")
df1 = df[1]
df2 = df[2]
data = data.frame(df1)[,-c(1,2)]
data_full = data.frame(df1)
df_pere = data_full[which(data_full[,2] == "Le Père Duchesne"),]
df_vieux = data_full[which(data_full[,2] == "Le Vieux Cordelier"),]
data_pere = df_pere[,-c(1,2)]
data_vieux = df_vieux[,-c(1,2)]
library(DepthProc)
library(hexbin)
library(aplpack) # bagplot
library(robustbase)
library(MDBED)  # plot exponential bivariate distr+ibution
library(roahd)
library(MASS)
library(rgl)
grid <-  seq( 1, 12, length.out =  12)
f_data = fData(grid, data)
plot(f_data)
invisible(outliergram(f_data))
View(data)
spring = data[,c(6,7,8)]
library(robustbase)
spring = data[,c(6,7,8)]
fit_MCD <- covMcd(x = spring, alpha = .75, nsamp = "best")
fit_MCD
spring = data[,c(6,7,8)]
fit_MCD <- covMcd(x = spring, alpha = .75, nsamp = 1000)
fit_MCD
plot(fit_MCD, classic=TRUE, labels.id=FALSE, which="distance")
plot(fit_MCD,labels.id=FALSE,which=c("dd"))
View(fit_MCD)
View(fit_MCD)
plot(fit_MCD,labels.id=TRUE,which=c("dd"))
plot(fit_MCD,labels.id=FALSE,which=c("dd"))
library(survival)
library(survminer)
library(dplyr)
library(ggplot2)
library(knitr)
library(broom)
library(tidyr)
df = data.frame(df2)
df_pere = df[which(df[,2] =="Le Père Duchesne"),]
df_vieux = df[which(df[,2] != "Le Père Duchesne"),]
event = which(is.na(df[3]))
status <- rep(1, times=nrow(df))
status[event] = 0
df$status = status
fit <- survfit(Surv(df.tte.time.to.fall, status==1) ~ df.tte.Journal, data = df)
ggsurvplot(fit, conf.int = F, risk.table.col = "strata", legend='none')
ggsurvplot(fit, conf.int = F,
risk.table = TRUE, # Add risk table
risk.table.col = "strata", # Change risk table color by groups
surv.median.line = "hv", # Specify median survival
ggtheme = theme_bw(), # Change ggplot2 theme
break.time.by=90,
legend.labs=c("Pere","Vieux"), legend.title="Journal",
palette=c("darkblue","cyan3"),
title="Kaplan-Meier Curves ")
iter = 1000
N = nrow(df)
n1 = nrow(df1)
df_pooled = df
T_perm = numeric(iter)
T0 = survdiff(Surv(df.tte.time.to.fall, status==1) ~ df.tte.Journal, data = df)
for (i in 1:iter){
perm = sample(N)
df_perm = df[perm,]
log_rank_test <- survdiff(Surv(df.tte.time.to.fall, status==1) ~ df.tte.Journal, data = df_perm)
T_perm[i] = log_rank_test$chisq
}
# p-value
p_val <- sum(T_perm>=T0)/iter
iter = 1000
N = nrow(df)
n1 = nrow(df1)
df_pooled = df
T_perm = numeric(iter)
T0 = survdiff(Surv(df.tte.time.to.fall, status==1) ~ df.tte.Journal, data = df)$chisq
for (i in 1:iter){
perm = sample(N)
df_perm = df[perm,]
log_rank_test <- survdiff(Surv(df.tte.time.to.fall, status==1) ~ df.tte.Journal, data = df_perm)
T_perm[i] = log_rank_test$chisq
}
# p-value
p_val <- sum(T_perm>=T0)/iter
p_val
View(df)
View(df2)
View(df1)
View(data_vieux)
data_cami = data_vieux[1,]
View(data_cami)
library(ISLR2)
library(car)
library(np)
library(splines)
library(fda)
library(magrittr)
library(KernSmooth)
View(data_cami)
x = seq(1,12, by=1)
data_cami$rbind(x)
rbind(data_camix)
rbind(data_cami,x)
data_cami = data_vieux[1,]
x = seq(1,12, by=1)
rbind(data_cami,x)
View(data_cami)
data_cami = data_vieux[1,]
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
data_cami = data_vieux[1,]
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
rbind(data_cami,x)
m_loc = npreg("18" ~ "2", # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1.5, # bandwidth # TRY DECREASING THE BANDWIDTH
data = dt)
data_cami = data_vieux[1,]
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
rbind(data_cami,x)
m_loc = npreg("18" ~ "2", # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1.5, # bandwidth # TRY DECREASING THE BANDWIDTH
data = t(dt))
m_loc = npreg(data_cami[1,] ~ x, # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1.5, # bandwidth # TRY DECREASING THE BANDWIDTH
)
data_cami = data_vieux[1,]
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
rbind(data_cami,x)
m_loc = npreg(data_cami[1,] ~ x, # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1.5 # bandwidth # TRY DECREASING THE BANDWIDTH
)
help(npreg)
dt = data.frame(x = x, y = data_cami)
View(dt)
data_cami = data_vieux[1,]
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
dt = data.frame(x = x, y = data_cami)
rbind(data_cami,x)
m_loc = npreg(y ~ x, # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1.5 # bandwidth # TRY DECREASING THE BANDWIDTH
dt)
data_cami = data_vieux[1,]
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
dt = data.frame(x = x, y = data_cami)
rbind(data_cami,x)
m_loc = npreg(y ~ x, # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1,5 # bandwidth # TRY DECREASING THE BANDWIDTH
dt)
data_cami = data_vieux[1,]
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
dt = data.frame(x = x, y = data_cami)
rbind(data_cami,x)
m_loc = npreg(y ~ x, # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1,5, # bandwidth # TRY DECREASING THE BANDWIDTH
dt)
View(dt)
data_cami = as.matrix(data_vieux[1,])
data_cami = as.matrix(data_vieux[1,])
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
dt = data.frame(x = x, y = data_cami)
rbind(data_cami,x)
m_loc = npreg(y ~ x, # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1,5, # bandwidth # TRY DECREASING THE BANDWIDTH
dt)
dt = rbind(data_cami,x)
dt = t(dt)
data_cami = as.matrix(data_vieux[1,])
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
dt = t(dt)
rbind(data_cami,x)
m_loc = npreg("18" ~ x, # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1,5, # bandwidth # TRY DECREASING THE BANDWIDTH
dt)
colnames(dt)
data_cami = as.matrix(data_vieux[1,])
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
dt = t(dt)
rbind(data_cami,x)
m_loc = npreg(18 ~ x, # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1,5, # bandwidth # TRY DECREASING THE BANDWIDTH
dt)
data_cami = as.matrix(data_vieux[1,])
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
dt = t(dt)
m_loc = npreg("18" ~ "x", # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1,5, # bandwidth # TRY DECREASING THE BANDWIDTH
dt)
data_cami = as.matrix(data_vieux[1,])
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
dt = t(dt)
m_loc = npreg("18" ~ "x", # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1.5, # bandwidth # TRY DECREASING THE BANDWIDTH
dt)
data_cami = data_vieux[1,]
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
dt = t(dt)
m_loc = npreg("18" ~ "x", # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1.5, # bandwidth # TRY DECREASING THE BANDWIDTH
dt)
data_cami = data_vieux[1,]
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
m_loc = npreg("18" ~ "x", # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1.5, # bandwidth # TRY DECREASING THE BANDWIDTH
dt)
dt = t(dt)
dt = data.frame(t(dt))
m_loc = npreg("18" ~ "x", # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1.5, # bandwidth # TRY DECREASING THE BANDWIDTH
dt)
View(dt)
m_loc = npreg("18" ~ 1, # sono la y e la x di un dataset, nel nostro caso Prestige (fai p = Prestige per aprirti il dataset vero e proprio)
ckertype = 'gaussian', # tipo di kernel regression
bws = 1.5, # bandwidth # TRY DECREASING THE BANDWIDTH
data_cami)
data_cami = data_vieux[1,]
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
dt = data.frame(t(dt))
d = data.frame(x = )
data_cami = data_vieux[1,]
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
dt = data.frame(t(dt))
m_loc = npreg("18" ~ 1,
ckertype = 'gaussian',
bws = 1.5,
data_cami)
View(data_vieux)
data_cami = data_vieux[1,]
x = seq(1,12, by=1)
dt = rbind(data_cami,x)
dt = data.frame(t(dt))
m_loc = npreg(
ckertype = 'gaussian',
bws = 1.5,
data_cami)
View(data_cami)
setwd("~/Desktop/Bayesian/Tancredi")
library(MASS)
library(openxlsx)
set.seed(2024)
J = 15
q = 3
K = 5
L = 4
w <- matrix(c(0.25, 0.25, 0.25, 0.25,
1/3, 1/3, 1/3, 0,
0, 1/3, 1/3, 1/3,
0, 0.5, 0.5, 0,
0, 0.5, 0.5, 0), nrow = 5, byrow=T)
cat_w <- 1:L
pi <- c(0.2, 0.2, 0.2, 0.2, 0.2)
cat_pi <- 1:K
nj <- c(3:5, 3:5, 3:5, 3:5, 3:5)
mu1 <- numeric(3)
mu2 <- c(9:11)
sigma1 <- diag(1, nrow = q, ncol = q)
sigma2 <- matrix(c(16, 4, 4, 4, 9, 2, 4, 2, 9), nrow = 3, byrow = TRUE)
nrow_data <- sum(nj)
temp <- numeric(nrow_data)
data <- data.frame(Subject = temp, c1 = temp, c2 = temp, c3 = temp, DC = temp, OC = temp)
pos = 0
for (j in 1:J){
s1 <- sample(cat_pi, size = 1, prob = pi)
for(i in 1:nj[j]){
pos <- pos+1
s2 <- sample(cat_w, size = 1, prob = w[s1,])
data$DC[pos] <- s1
data$OC[pos] <- s2
data$Subject[pos] <- j
if (s2 == 1)
c <- mvrnorm(n = 1, mu = mu1, Sigma = sigma1)
if (s2 == 2)
c <- mvrnorm(n = 1, mu = mu1, Sigma = sigma2)
if (s2 == 3)
c <- mvrnorm(n = 1, mu = mu2, Sigma = sigma1)
if (s2 == 4)
c <- mvrnorm(n = 1, mu = mu2, Sigma = sigma2)
data$c1[pos] <- c[1]
data$c2[pos] <- c[2]
data$c3[pos] <- c[3]
}
}
#save as an excell
write.csv(data, file = "test_data_con_tutto.csv", row.names = FALSE)
